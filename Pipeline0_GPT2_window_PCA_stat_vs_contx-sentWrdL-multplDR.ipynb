{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "jewish-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and initializations\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import glob\n",
    "import librosa\n",
    "import itertools as itt\n",
    "import torch\n",
    "import transformers\n",
    "from torch.nn import functional as F\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy as sp\n",
    "\n",
    "sent_Window=1 # windowing will happen by expanding sentences rather than words if 0 it's words rather than windows.\n",
    "PCAV=1 # take pca of values or not\n",
    "modelplus='-medium' # model type\n",
    "#modelplus='' # model type\n",
    "Twolayer=1\n",
    "if Twolayer==1:\n",
    "    TwolayerN='_2LYR'\n",
    "else:\n",
    "    TwolayerN=''\n",
    "if sent_Window==1:\n",
    "    sent_Window_N='WsentL'+TwolayerN\n",
    "elif sent_Window==0:\n",
    "    sent_Window_N='WwrdL'+TwolayerN\n",
    "else:\n",
    "    sent_Window_N='ent'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "permanent-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the GPT model to use:\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2'+modelplus, output_hidden_states=True)\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproducible results during evaluation!\n",
    "model.eval()\n",
    "\n",
    "Dictname='../linfo.pkl'\n",
    "Lingname='../Data/after_aligner/hank.pickle'\n",
    "#model = pickle.load(open(Dictname, 'rb'))\n",
    "\n",
    "with open(Lingname, 'rb') as handle:\n",
    "    datadict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extreme-emission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stim08', 'stim09', 'stim19', 'stim18', 'stim01', 'stim15', 'stim14', 'stim16', 'stim02', 'stim03', 'stim17', 'stim13', 'stim07', 'stim06', 'stim12', 'stim04', 'stim10', 'stim11', 'stim05']\n",
      "['stim08', 'stim09', 'stim19', 'stim18', 'stim16', 'stim02', 'stim03', 'stim17', 'stim01', 'stim15', 'stim14', 'stim04', 'stim10', 'stim11', 'stim05', 'stim13', 'stim07', 'stim06', 'stim12']\n",
      "[0, 1, 2, 3, 7, 8, 9, 10, 4, 5, 6, 15, 16, 17, 18, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "# load the sentenced scripts:\n",
    "add_sent='../Data/hank_scripts_proper/'\n",
    "sent_names=glob.glob(add_sent+'*.txt')\n",
    "\n",
    "\n",
    "namename=[idd[-10:-4] for idd in sent_names]\n",
    "print(namename)\n",
    "\n",
    "print(datadict['name'])\n",
    "\n",
    "order=[namename.index(idd) for idd in datadict['name']]\n",
    "print(order)\n",
    "\n",
    "sent_names=[sent_names[idd] for idd in order]\n",
    "\n",
    "#_, _, filenames = next(walk(add_sent))\n",
    "stories=[]\n",
    "for fn in sent_names:\n",
    "    with open(fn) as f:\n",
    "        stories.append(f.read().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "indian-helen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 5, 6, 11, 14, 17, 16, 0, 1, 12, 13, 18, 15, 10, 9, 4, 7, 3, 2]\n",
      "['stim01', 'stim02', 'stim03', 'stim04', 'stim05', 'stim06', 'stim07', 'stim08', 'stim09', 'stim10', 'stim11', 'stim12', 'stim13', 'stim14', 'stim15', 'stim16', 'stim17', 'stim18', 'stim19']\n",
      "2682 2682\n"
     ]
    }
   ],
   "source": [
    "# concatenate all the stories in their correct order:\n",
    "organized_order=[ datadict['name'].index('stim0'+str(idd)) if idd<10 else datadict['name'].index('stim'+str(idd)) for idd in range(1,len(datadict['name'])+1)]\n",
    "\n",
    "print(organized_order)\n",
    "org_storyN=[ datadict['name'][idd] for idd in organized_order]\n",
    "print(org_storyN)\n",
    "org_stories=[stories[idd] for idd in organized_order]\n",
    "comp_story=' '.join(org_stories)\n",
    "#print(comp_story)\n",
    "org_str_wrds=[idd.split(' ') for idd in org_stories ]\n",
    "org_str_len=[ len(idd) for idd in org_str_wrds]\n",
    "str_wrds=[ j for i in org_str_wrds for j in i]\n",
    "str_wrds2=[ ''.join(c for c in idd if c.isalpha()) if len(idd)>1 else idd for idd in str_wrds]\n",
    "print(len(str_wrds), sum(org_str_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "formal-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actual words in the story: 1241 2682\n",
      "number of words in the story that are repeated at least 4 times: 56 [[5, 'hank'], [9, 'dog'], [11, 'got'], [11, 'ranch'], [9, 'know'], [4, 'mean'], [6, 'took'], [5, 'job'], [6, 'head'], [5, 'security'], [15, 'could'], [4, 'tail'], [7, 'kind'], [6, 'nose'], [5, 'two'], [5, 'get'], [5, 'little'], [7, 'around'], [8, 'would'], [7, 'drover'], [4, 'anyway'], [4, 'made'], [10, 'right'], [4, 'night'], [10, 'heard'], [9, 'went'], [7, 'came'], [4, 'find'], [4, 'come'], [9, 'well'], [4, 'side'], [4, 'go'], [4, 'santiago'], [14, 'one'], [6, 'door'], [11, 'back'], [4, 'enough'], [4, 'kitchen'], [6, 'sally'], [6, 'may'], [6, 'table'], [8, 'sure'], [4, 'guy'], [4, 'years'], [5, 'never'], [5, 'dinner'], [4, 'take'], [4, 'ran'], [5, 'hear'], [4, 'think'], [4, 'house'], [4, 'tracks'], [4, 'say'], [4, 'country'], [6, 'cave'], [6, 'music']]\n"
     ]
    }
   ],
   "source": [
    "all_wrds=comp_story.split(' ')\n",
    "all_wrds2=[ ''.join(c for c in idd if c.isalpha()) for idd in all_wrds]\n",
    "#print(all_wrds2)\n",
    "def unique(list1):\n",
    " \n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "unique_wrds=unique(all_wrds2)\n",
    "all_actual_wrds=[idd for idd in all_wrds2 if idd not in stopwords.words('english')]\n",
    "print( 'number of actual words in the story:', len(all_actual_wrds),len(all_wrds2) )\n",
    "#print('unique of all words:,unique(all_wrds2))\n",
    "rep=[]\n",
    "for wrd in unique_wrds:\n",
    "    inst=[idd for idd,item in enumerate(all_wrds2) if item==wrd ]\n",
    "    rep.append([len(inst), wrd])\n",
    "\n",
    "rep_=[idd for idd in rep if idd[1] not in stopwords.words('english') ]\n",
    "rep_Gthan4=[ idd for idd in rep_ if idd[0]>3]\n",
    "\n",
    "print('number of words in the story that are repeated at least 4 times:', len(rep_Gthan4), rep_Gthan4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "framed-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentecnes:  306\n",
      "it is me again hank the cow dog\n"
     ]
    }
   ],
   "source": [
    "#print(str_wrds[0:50])\n",
    "# make sentences, and address of sentence for each word\n",
    "sent_counter=0\n",
    "wrd_in_sent=[]\n",
    "sentences=[]\n",
    "in_sent_idd=[]\n",
    "counter_in_sent_idd=0\n",
    "sent_inst=[]\n",
    "for item in str_wrds:\n",
    "    \n",
    "    wrd_in_sent.append(sent_counter)\n",
    "    sent_inst.append(item)\n",
    "    in_sent_idd.append(counter_in_sent_idd)\n",
    "    counter_in_sent_idd=counter_in_sent_idd+1\n",
    "    if '.' in item:\n",
    "        counter_in_sent_idd=0\n",
    "        sent_counter=sent_counter+1\n",
    "        sentences.append(sent_inst)\n",
    "        sent_inst=[]\n",
    "#print(wrd_in_sent[0:50])\n",
    "print('number of sentecnes: ',len(sentences))\n",
    "idd=7\n",
    "nw=0\n",
    "#print(sentences[max(wrd_in_sent[idd]-nw,0):wrd_in_sent[idd]])\n",
    "#print(sentences[wrd_in_sent[idd]][:in_sent_idd[idd]]+[str_wrds2[idd]])\n",
    "WindowSent=sentences[max(wrd_in_sent[idd]-nw,0):wrd_in_sent[idd]]+[sentences[wrd_in_sent[idd]][:in_sent_idd[idd]]+[str_wrds2[idd]]]\n",
    "WindowSent=[j for i in WindowSent for j in i]\n",
    "print(' '.join(WindowSent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "powerful-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw=20\n",
    "if nw>=0:\n",
    "        wrd_enc=[]\n",
    "        for idd, item in enumerate(str_wrds2):\n",
    "            WindowSent=sentences[max(wrd_in_sent[idd]-nw,0):wrd_in_sent[idd]]+[sentences[wrd_in_sent[idd]][:in_sent_idd[idd]]+[item]]\n",
    "            WindowSent=[j for i in WindowSent for j in i]\n",
    "            wrd_enc.append(tokenizer.encode(' '.join(WindowSent), add_special_tokens = True,\n",
    "                                             truncation =True,\n",
    "                                             add_prefix_space=True, return_tensors = \"pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "strange-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "bye\n",
      "hi\n",
      "bye\n",
      "hi\n",
      "bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'text=\\'hello.\\n\\'\\ninput = tokenizer.encode(text, add_special_tokens = True,\\n                                 truncation =True,\\n                     add_prefix_space=True,\\n                               return_tensors = \"pt\")\\nwith torch.no_grad():\\n    output = model(input)\\n#a=tokenizer.decode(input[0]).split(\\' \\')\\n#new_words=[idd[2][1:-1].lower() for idd in datadict[\\'words\\'][i] if idd[2][1:-1]!=\\'sp\\']\\n#a=[ \\'\\'.join(c for c in idd if c.isalpha()) for idd in a]\\na=input[0].cpu().detach().numpy()\\nprint(input, a)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the activation too all these words:\n",
    "\n",
    "\n",
    "'''wrd_enc=[tokenizer.encode(' '.join(str_wrds[max(idd-nw,0):idd]+[item]), add_special_tokens = True,\n",
    "                                         truncation =True,\n",
    "                                         add_prefix_space=True, return_tensors = \"pt\") for idd, item in enumerate(str_wrds2)]\n",
    "'''\n",
    "output=[]\n",
    "if sent_Window==1:\n",
    "    TKN=[]\n",
    "    Window=[-1, 0, 10] # -1 means the words on their own.\n",
    "    #text2=[ ''.join(c for c in idd if c.isalpha()) for idd in text]\n",
    "    for nw in Window:\n",
    "        print('hi')\n",
    "        if nw>=0:\n",
    "            wrd_enc=[]\n",
    "            for idd, item in enumerate(str_wrds2):\n",
    "                WindowSent=sentences[max(wrd_in_sent[idd]-nw,0):wrd_in_sent[idd]]+[sentences[wrd_in_sent[idd]][:in_sent_idd[idd]]+[item]]\n",
    "                WindowSent=[j for i in WindowSent for j in i]\n",
    "                if len(WindowSent)>900:\n",
    "                    print('for window:',nw,' length is ', len(WindowSent) )\n",
    "                    WindowSent=WindowSent[-900:]\n",
    "                text_inp=tokenizer.encode(' '.join(WindowSent), add_special_tokens = True,\n",
    "                                                 truncation =True,\n",
    "                                                 add_prefix_space=True, return_tensors = \"pt\")\n",
    "                if len(text_inp[0])>=1024:\n",
    "                    print(\" maximum input length violated\")\n",
    "\n",
    "                wrd_enc.append(text_inp)\n",
    "        else:\n",
    "            wrd_enc=[tokenizer.encode(' '.join([item]), add_special_tokens = True,\n",
    "                                             truncation =True,\n",
    "                                             add_prefix_space=True, return_tensors = \"pt\") for idd, item in enumerate(str_wrds2)]\n",
    "\n",
    "        outputs=[]\n",
    "        with torch.no_grad():\n",
    "            for idd,item in enumerate(wrd_enc):\n",
    "                if Twolayer==1:\n",
    "                    outputs.append( [model(item)[2][0][:,-1,:].cpu().detach().numpy(),model(item)[2][-1][:,-1,:].cpu().detach().numpy() ])\n",
    "                else:\n",
    "                    outputs.append( [igg[:,-1,:].cpu().detach().numpy() for igg in model(item)[2]])\n",
    "            #model(item)[2][0][:,-1,:],model(item)[2][12][:,-1,:]\n",
    "        output.append(outputs)\n",
    "        TKN.append(wrd_enc)\n",
    "        print('bye')\n",
    "elif sent_Window==0:\n",
    "    TKN=[]\n",
    "    Window=[0, 2, 5,10,20, 50,100,200, 500,900] # -1 means the words on their own.\n",
    "    #text2=[ ''.join(c for c in idd if c.isalpha()) for idd in text]\n",
    "    for nw in Window:\n",
    "        print('hi')\n",
    "        if nw>=0:\n",
    "            wrd_enc=[]\n",
    "            for idd, item in enumerate(str_wrds2):\n",
    "                text_inp=tokenizer.encode(' '.join(str_wrds[max(idd-nw,0):idd]+[item]), add_special_tokens = True,\n",
    "                                         truncation =True,\n",
    "                                         add_prefix_space=True, return_tensors = \"pt\")\n",
    "                if len(text_inp[0])>=1024:\n",
    "                    print(\" maximum input length violated\")\n",
    "\n",
    "                wrd_enc.append(text_inp)\n",
    "        outputs=[]\n",
    "        with torch.no_grad():\n",
    "            for idd,item in enumerate(wrd_enc):\n",
    "                outputs.append( [igg[:,-1,:].cpu().detach().numpy() for igg in model(item)[2]])\n",
    "            #model(item)[2][0][:,-1,:],model(item)[2][12][:,-1,:]\n",
    "        output.append(outputs)\n",
    "        TKN.append(wrd_enc)\n",
    "        print('bye')\n",
    "else:\n",
    "    Window=[]\n",
    "\n",
    "\n",
    "'''text='hello.\\n'\n",
    "input = tokenizer.encode(text, add_special_tokens = True,\n",
    "                                 truncation =True,\n",
    "                     add_prefix_space=True,\n",
    "                               return_tensors = \"pt\")\n",
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "#a=tokenizer.decode(input[0]).split(' ')\n",
    "#new_words=[idd[2][1:-1].lower() for idd in datadict['words'][i] if idd[2][1:-1]!='sp']\n",
    "#a=[ ''.join(c for c in idd if c.isalpha()) for idd in a]\n",
    "a=input[0].cpu().detach().numpy()\n",
    "print(input, a)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "operational-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WsentL_2LYR\n",
      "[-1, 0, 10, -2]\n"
     ]
    }
   ],
   "source": [
    "print(sent_Window_N)\n",
    "print(Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "headed-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839\n",
      "838\n",
      "827\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "#print(len(output[0])) # [output]= nWindows*nWrds*2(0+last)*1*nNeurons\n",
    "# adding the whole story representationto output\n",
    "#\n",
    "output_all2_start=0\n",
    "for portion in range(0,len(str_wrds2),800):\n",
    "    text=' '.join(str_wrds2[portion:portion+800])\n",
    "    input = tokenizer.encode(text, add_special_tokens = True,\n",
    "                                         truncation =True,\n",
    "                             add_prefix_space=True,\n",
    "                                       return_tensors = \"pt\")\n",
    "    print(len(input[0]))\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output_all = model(input)\n",
    "        if output_all2_start==0:\n",
    "            LAyers=[0, -1]#range(len(output_all[2]))\n",
    "            output_all2=[output_all[2][idd].cpu().detach().numpy() for idd in LAyers ] #layer, batch, nToken, neuron\n",
    "            a=input[0].cpu().detach().numpy()\n",
    "            output_all2_start=output_all2_start+1\n",
    "        else:\n",
    "            output_all2=[np.concatenate( ( output_all2[idd],output_all[2][idd].cpu().detach().numpy()), axis=1) for idd in LAyers ]\n",
    "            a=np.concatenate( (a,input[0].cpu().detach().numpy()), axis=0)\n",
    "        ##a=tokenizer.decode(input[0]).split(' ')\n",
    "        #new_words=[idd[2][1:-1].lower() for idd in datadict['words'][i] if idd[2][1:-1]!='sp']\n",
    "        ##a=[ ''.join(c for c in idd if c.isalpha()) for idd in a]\n",
    "\n",
    "wrd_enc=[tokenizer.encode(item, add_special_tokens = True,\n",
    "                                 truncation =True,add_prefix_space=True,\n",
    "                               return_tensors = \"pt\")[0].cpu().detach().numpy() for item in str_wrds2]\n",
    "wrd_enc=[ item[-1] for item in wrd_enc ]\n",
    "counter=0\n",
    "tknIdx=[]\n",
    "a=[j for j in a]\n",
    "counter=0\n",
    "tknIdx=[]\n",
    "act_all=[]\n",
    "for wrd in wrd_enc:\n",
    "    if wrd in a[counter:]:\n",
    "        idd=a[counter:].index(wrd)\n",
    "        tknIdx.append(idd+counter)\n",
    "        act_all.append([item_layer[:,idd+counter,:] for item_layer in output_all2])\n",
    "        counter=counter+idd+1\n",
    "    else:\n",
    "        print('wrd not in tokenizer output')\n",
    "output.append(act_all)\n",
    "Window.append(-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surface-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(output_all[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expected-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of neurons: 1024\n",
      " number of layers: 2\n"
     ]
    }
   ],
   "source": [
    "# [output]= nWindows*nWrds*2(layer 0 and last)*1*nNeurons\n",
    "# making output numpy\n",
    "nNeurons=(output[0][0][0]).shape[1]\n",
    "print(' number of neurons:',nNeurons )\n",
    "nLYR=len(output[0][0])\n",
    "print(' number of layers:',nLYR )\n",
    "activation=np.zeros((len(Window),len(str_wrds2), nLYR, nNeurons ))\n",
    "for wndID,wnd in enumerate(Window):\n",
    "    for wrdID in range(len(str_wrds2)):\n",
    "        for layer in range(nLYR):\n",
    "            activation[wndID,wrdID,layer, :] =output[wndID][wrdID][layer]#.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "declared-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2682, 2, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(activation.shape)\n",
    "#print(len(sentences),name)\n",
    "#\n",
    "from scipy.io import savemat\n",
    "all_wrds_dict={'actv':[]}\n",
    "all_wrds_dict['actv']=activation\n",
    "all_wrds_dict['nonStopWrds']=np.asarray([1 if idd not in stopwords.words('english') else 0 for idd in str_wrds2])\n",
    "all_wrds_dict['all_wrds']=str_wrds2\n",
    "all_wrds_dict['window']=Window\n",
    "all_wrds_dict['sents']=sentences\n",
    "Savename='../Data/after_aligner/hankGPT2'+modelplus+'FN'+sent_Window_N+'_allWords_beforeDR'+'.mat'\n",
    "# save the files to .mat \n",
    "#print(all_wrds_dict)\n",
    "savemat(Savename, all_wrds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "assured-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wnd=0\\nfrom sklearn.manifold import TSNE\\nimport pandas as pd\\nfrom colour import Color\\nimport matplotlib as mpl\\nfrom mpl_toolkits.mplot3d import Axes3D\\n\\nred = Color(\"red\")\\ncolors = list(red.range_to(Color(\"green\"),len(sentences)))\\n%matplotlib notebook\\nfig = plt.figure(figsize=(5,5))\\n\\n    \\nfor layr in range(activation.shape[2]):\\n    X = np.squeeze(activation[:,:,layr,:])\\n    tsne=TSNE(n_components=3)\\n    Xn = tsne.fit_transform(X)\\n    #axs[SNR, layr].axes(projection=\\'3d\\')\\n    ax = fig.add_subplot(5,3 , layr+1, projection=\\'3d\\')\\n    ax.plot3D(Red_act_ref[:,0], Red_act_ref[:,1], Red_act_ref[:,2], \\'gray\\')\\n    ax.text(Red_act_ref[-1,0], Red_act_ref[-1,1], Red_act_ref[-1,2], \"end_ref\", color=\\'red\\')\\n    ax.plot3D(Red_act_test[:,0], Red_act_test[:,1], Red_act_test[:,2], \\'gray\\')\\n    ax.text(Red_act_test[-1,0], Red_act_test[-1,1], Red_act_test[-1,2], \"end_test\", color=\\'red\\')\\n    \\n    \\nlayr=12\\nX = np.squeeze(activation[:,:,layr,:])\\ntsne=TSNE(n_components=3)\\nXn = tsne.fit_transform(X)\\nax = fig.add_subplot(5,3 , layr+1)\\nax = Axes3D(fig)\\n#ax.scatter(Xn[:,0].T, Xn[:,1].T,marker=\\'o\\')\\ndf = pd.DataFrame(dict(x=Xn[:,0].T, y=Xn[:,1].T, z=Xn[:,2].T, label=wrd_in_sent))\\n\\ngroups = df.groupby(\\'label\\')\\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\\nfor name, group in groups:\\n    #print(name)\\n    ax.scatter(group.x, group.y,group.z,s=3)\\nfor wrdID,wrd in enumerate(str_wrds):\\n    ax.text(Xn[wrdID,0],Xn[wrdID,1],Xn[wrdID,2],  \\'%s\\' % (wrd), size=3, zorder=1, color=\\'k\\')\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the representations of sentences and words throughout the network:\n",
    "# firs we look at the tsnes through the layers:\n",
    "'''wnd=0\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from colour import Color\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "red = Color(\"red\")\n",
    "colors = list(red.range_to(Color(\"green\"),len(sentences)))\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "    \n",
    "for layr in range(activation.shape[2]):\n",
    "    X = np.squeeze(activation[:,:,layr,:])\n",
    "    tsne=TSNE(n_components=3)\n",
    "    Xn = tsne.fit_transform(X)\n",
    "    #axs[SNR, layr].axes(projection='3d')\n",
    "    ax = fig.add_subplot(5,3 , layr+1, projection='3d')\n",
    "    ax.plot3D(Red_act_ref[:,0], Red_act_ref[:,1], Red_act_ref[:,2], 'gray')\n",
    "    ax.text(Red_act_ref[-1,0], Red_act_ref[-1,1], Red_act_ref[-1,2], \"end_ref\", color='red')\n",
    "    ax.plot3D(Red_act_test[:,0], Red_act_test[:,1], Red_act_test[:,2], 'gray')\n",
    "    ax.text(Red_act_test[-1,0], Red_act_test[-1,1], Red_act_test[-1,2], \"end_test\", color='red')\n",
    "    \n",
    "    \n",
    "layr=12\n",
    "X = np.squeeze(activation[:,:,layr,:])\n",
    "tsne=TSNE(n_components=3)\n",
    "Xn = tsne.fit_transform(X)\n",
    "ax = fig.add_subplot(5,3 , layr+1)\n",
    "ax = Axes3D(fig)\n",
    "#ax.scatter(Xn[:,0].T, Xn[:,1].T,marker='o')\n",
    "df = pd.DataFrame(dict(x=Xn[:,0].T, y=Xn[:,1].T, z=Xn[:,2].T, label=wrd_in_sent))\n",
    "\n",
    "groups = df.groupby('label')\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    #print(name)\n",
    "    ax.scatter(group.x, group.y,group.z,s=3)\n",
    "for wrdID,wrd in enumerate(str_wrds):\n",
    "    ax.text(Xn[wrdID,0],Xn[wrdID,1],Xn[wrdID,2],  '%s' % (wrd), size=3, zorder=1, color='k')\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "portable-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dimention reduction methods:\n",
    "DimRs=['PCA_mr','PCA_n', 'PCA','MDS', 'LLE', 'PPA+PCA' ]\n",
    "# these methods are gonna be added on the Window dimension since we are using only one window dim. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "revised-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2682, 2, 1024)\n",
      "(10728, 2, 1024)\n",
      "(1, 2, 1024)\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(4, 2682, 2, 1024)\n",
      "activation_mr (4, 2682, 2, 1024)\n"
     ]
    }
   ],
   "source": [
    "print((activation.shape)) # wind, words, layer, neurons. \n",
    "#take the PCA\n",
    "# first we concatinate all the words and windows for the two layers:\n",
    "Act=activation.reshape((-1,nLYR,nNeurons))\n",
    "print(Act.shape)\n",
    "\n",
    "# find the norms of eacl neauron at each layer:\n",
    "Norm_act=np.linalg.norm(Act,axis=0)\n",
    "print(Norm_act[None,:,:].shape)\n",
    "# normalize Act and activation:\n",
    "Act_n=Act/Norm_act[None,:,:]\n",
    "activation_n=activation/Norm_act[None,None,:,:]\n",
    "tmp=activation_n.reshape((-1,nLYR,nNeurons))\n",
    "print(np.linalg.norm(tmp,axis=0))\n",
    "\n",
    "\n",
    "\n",
    "## z-score activation:\n",
    "Act_m=np.mean(Act,axis=0)\n",
    "Act_std=np.std(Act,axis=0)\n",
    "\n",
    "activation_zs=(activation-Act_m[None,None,:,:])/Act_std[None,None,:,:]\n",
    "#activation_zs=sp.stats.zscore(activation,axis=1) # WARNING: it is assumed that the first dimmension is 1\n",
    "print((activation_zs.shape))\n",
    "\n",
    "\n",
    "## mean removed:\n",
    "activation_mr=activation-Act_m[None,None,:,:] # WARNING: it is assumed that the first dimmension is 1\n",
    "print('activation_mr',activation_mr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "processed-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window length must be 1. it is: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_mr=activation_mr[-1,:,:,:]\n",
    "activation_mr=activation_mr[-1,:,:,:]\n",
    "\n",
    "print('Window length must be 1. it is:', len(Window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "premium-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " initial ncmp for PPA is:  1024\n",
      "[312, 1]\n",
      "activation_PPA shape is  (4, 2682, 2, 1024)\n",
      "(4, 2682, 2, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we first check how much of the zscored data's variance is explaind by each PC:\n",
    "# then apply PPA and zscore\n",
    "ncmp=nNeurons\n",
    "print(' initial ncmp for PPA is: ', ncmp)\n",
    "from sklearn.decomposition import PCA\n",
    "PCAs=[]\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "Threshold=0.95\n",
    "D=[]\n",
    "\n",
    "for layer in range(nLYR):\n",
    "    pca=PCA(n_components=ncmp)\n",
    "    pca.fit(np.squeeze(activation_mr.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "    PCAs.append(pca)\n",
    "    cumSumVar=pca.explained_variance_ratio_.cumsum()\n",
    "    thresholed=[idd for idd,item in enumerate(cumSumVar) if item>Threshold]\n",
    "    D.append(thresholed[0])\n",
    "    axs[layer].plot(pca.explained_variance_ratio_)\n",
    "    axs[layer].set_title('explained var for layer:'+str(layer))\n",
    "print(D)    \n",
    "    \n",
    "# apply PPA:\n",
    "activation_PPA=np.zeros((len(Window),len(str_wrds2), nLYR, ncmp ))\n",
    "#[PCAs[0].components_]= ncmp*ndim(original)\n",
    "for wnd in range(len(Window)):\n",
    "    for layer in range(nLYR):\n",
    "        activation_PPA[wnd,:,layer, :]=np.squeeze(activation_mr[wnd,:,layer, :])-PCAs[layer].transform(np.squeeze(activation_mr[wnd,:,layer, :]))[:,:D[layer]+1]@ PCAs[layer].components_[:D[layer]+1,:]\n",
    "\n",
    "print('activation_PPA shape is ', activation_PPA.shape)\n",
    "\n",
    "# do the PCA to see how the variance compares:\n",
    "PCAsofPPA=[]\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "ncmp=60\n",
    "for layer in range(nLYR):\n",
    "    pca=PCA(n_components=ncmp)\n",
    "    pca.fit(np.squeeze(activation_PPA.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "    PCAsofPPA.append(pca)\n",
    "    axs[layer].plot(PCAs[layer].explained_variance_ratio_[:ncmp])\n",
    "    axs[layer].plot(pca.explained_variance_ratio_)\n",
    "    axs[layer].set_title('explained var for layer:'+str(layer))\n",
    "    axs[layer].legend(['original', 'after PPA'])\n",
    "    \n",
    "# zscore PPA:\n",
    "Act_PPA=activation_PPA.reshape((-1,nLYR,nNeurons))\n",
    "Act_PPA_m=np.mean(Act,axis=0)\n",
    "Act_PPA_std=np.std(Act,axis=0)\n",
    "activation_PPA_zs=(activation_PPA-Act_PPA_m[None,None,:,:])/Act_PPA_std[None,None,:,:]\n",
    "print((activation_PPA_zs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "useful-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying PCA_mr:\n",
      "applying PCA_n:\n",
      "applying PCA:\n",
      "applying MDS:\n",
      "applying LLE:\n",
      "applying PPA+PCA:\n"
     ]
    }
   ],
   "source": [
    "## apply the dimension reductions:\n",
    "ncmp=60\n",
    "pcaName='DRs'\n",
    "#DimRs=['PCA_mr','PCA_n', 'PCA','MDS', 'LLE', 'PPA+PCA' ]\n",
    "activation_r=np.zeros((len(DimRs),len(Window),len(str_wrds2), nLYR, ncmp ))\n",
    "for idDR, DR_name in enumerate(DimRs):\n",
    "    if DR_name=='PCA_mr':\n",
    "        from sklearn.decomposition import PCA\n",
    "        PCAs=[]\n",
    "        for layer in range(nLYR):\n",
    "            pca=PCA(n_components=ncmp)\n",
    "            pca.fit(np.squeeze(activation_mr.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "            PCAs.append(pca)\n",
    "        \n",
    "        print('applying PCA_mr:')\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                    activation_r[idDR,wnd,:,layer, :]=PCAs[layer].transform(np.squeeze(activation_mr[wnd,:,layer, :]))    \n",
    "    if DR_name=='PCA_n':\n",
    "        from sklearn.decomposition import PCA\n",
    "        # now we transform the activation matrix:\n",
    "        print('applying PCA_n:')\n",
    "        PCAs=[]\n",
    "        for layer in range(nLYR):\n",
    "            pca=PCA(n_components=ncmp)\n",
    "            pca.fit(np.squeeze(activation_n.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "            PCAs.append(pca)\n",
    "\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                    activation_r[idDR,wnd,:,layer, :]=PCAs[layer].transform(np.squeeze(activation_n[wnd,:,layer, :]))\n",
    "    if DR_name=='PCA':\n",
    "        from sklearn.decomposition import PCA\n",
    "    \n",
    "        print('applying PCA:')\n",
    "        PCAs=[]\n",
    "        for layer in range(nLYR):\n",
    "            pca=PCA(n_components=ncmp)\n",
    "            pca.fit(np.squeeze(activation_zs.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "            PCAs.append(pca)\n",
    "\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                    activation_r[idDR,wnd,:,layer, :]=PCAs[layer].transform(np.squeeze(activation_zs[wnd,:,layer, :]))\n",
    "    if DR_name=='MDS':\n",
    "        from sklearn.metrics.pairwise import cosine_distances\n",
    "        from sklearn.manifold import MDS\n",
    "        # now we transform the activation matrix:\n",
    "        print('applying MDS:')\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                pca=MDS(n_components=ncmp,dissimilarity='precomputed')\n",
    "                activation_r[idDR,wnd,:,layer, :]=pca.fit_transform(cosine_distances(np.squeeze(activation[wnd,:,layer, :])))\n",
    "    if DR_name=='LLE':\n",
    "        from sklearn.manifold import LocallyLinearEmbedding\n",
    "        # now we transform the activation matrix:\n",
    "        print('applying LLE:')\n",
    "        PCAs=[]\n",
    "        for layer in range(nLYR):\n",
    "            pca=LocallyLinearEmbedding(n_components=ncmp)\n",
    "            pca.fit(np.squeeze(activation.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "            PCAs.append(pca)\n",
    "\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                    activation_r[idDR,wnd,:,layer, :]=PCAs[layer].transform(np.squeeze(activation[wnd,:,layer, :]))\n",
    "    if DR_name=='PPA+PCA':\n",
    "        \n",
    "        from sklearn.decomposition import PCA\n",
    "        # now we transform the activation matrix:\n",
    "        print('applying PPA+PCA:')\n",
    "        PCAs=[]\n",
    "        for layer in range(nLYR):\n",
    "            pca=PCA(n_components=ncmp)\n",
    "            pca.fit(np.squeeze(activation_PPA.reshape((-1,nLYR,nNeurons))[:,layer, :]))\n",
    "            PCAs.append(pca)\n",
    "\n",
    "        for wnd in range(len(Window)):\n",
    "            for layer in range(nLYR):\n",
    "                    activation_r[idDR,wnd,:,layer, :]=PCAs[layer].transform(np.squeeze(activation_PPA[wnd,:,layer, :]))\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "consecutive-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Applying PCA on each layer and keeping 60 PCs:\\nif PCAV==1:\\n    ncmp=60\\n    pcaName='Norm_pca'\\n    import numpy as np\\n    from sklearn.decomposition import PCA\\n    PCAs=[]\\n    activation_r=np.zeros((len(Window),len(str_wrds2), nLYR, ncmp ))\\n    for layer in range(nLYR):\\n        pca=PCA(n_components=ncmp)\\n        pca.fit(np.squeeze(Act_n[:,layer, :]))\\n        PCAs.append(pca)\\n    # now we transform the activation matrix:\\n    print('applying PCA:')\\n    for wndID,wnd in enumerate(Window):\\n        for wrdID in range(len(str_wrds2)):\\n            for layer in range(nLYR):\\n                activation_r[wndID,wrdID,layer, :]=PCAs[layer].transform(np.squeeze(activation_n[wndID,wrdID,layer, :])[np.newaxis,:])\\nelse:\\n    pcaName=''\\n    activation_r=np.zeros((len(Window),len(str_wrds2), nLYR, ncmp ))\\n    \\n    # now we transform the activation matrix:\\n    print('not applying PCA:')\\n    for wndID,wnd in enumerate(Window):\\n        for wrdID in range(len(str_wrds2)):\\n            for layer in range(nLYR):\\n                activation_r[wndID,wrdID,layer, :]=np.squeeze(activation[wndID,wrdID,layer, :])[np.newaxis,:]\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Applying PCA on each layer and keeping 60 PCs:\n",
    "if PCAV==1:\n",
    "    ncmp=60\n",
    "    pcaName='Norm_pca'\n",
    "    import numpy as np\n",
    "    from sklearn.decomposition import PCA\n",
    "    PCAs=[]\n",
    "    activation_r=np.zeros((len(Window),len(str_wrds2), nLYR, ncmp ))\n",
    "    for layer in range(nLYR):\n",
    "        pca=PCA(n_components=ncmp)\n",
    "        pca.fit(np.squeeze(Act_n[:,layer, :]))\n",
    "        PCAs.append(pca)\n",
    "    # now we transform the activation matrix:\n",
    "    print('applying PCA:')\n",
    "    for wndID,wnd in enumerate(Window):\n",
    "        for wrdID in range(len(str_wrds2)):\n",
    "            for layer in range(nLYR):\n",
    "                activation_r[wndID,wrdID,layer, :]=PCAs[layer].transform(np.squeeze(activation_n[wndID,wrdID,layer, :])[np.newaxis,:])\n",
    "else:\n",
    "    pcaName=''\n",
    "    activation_r=np.zeros((len(Window),len(str_wrds2), nLYR, ncmp ))\n",
    "    \n",
    "    # now we transform the activation matrix:\n",
    "    print('not applying PCA:')\n",
    "    for wndID,wnd in enumerate(Window):\n",
    "        for wrdID in range(len(str_wrds2)):\n",
    "            for layer in range(nLYR):\n",
    "                activation_r[wndID,wrdID,layer, :]=np.squeeze(activation[wndID,wrdID,layer, :])[np.newaxis,:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "single-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 2682, 2, 60)\n",
      "[8, 5, 6, 11, 14, 17, 16, 0, 1, 12, 13, 18, 15, 10, 9, 4, 7, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(activation_r.shape)\n",
    "print(organized_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adolescent-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding the word context gradually at the last layer:\n",
    "TKN=[]\n",
    "start_wrds=[]\n",
    "ACT=[]\n",
    "for i in range(len(stories)):\n",
    "    # find the start and end address in the concatinated story: str_wrds2\n",
    "    \n",
    "    new_words=[idd[2][1:-1].lower() for idd in datadict['words'][i] if idd[2][1:-1]!='sp']\n",
    "    # what story does it correspond to?\n",
    "    idx=organized_order.index(i)\n",
    "    idx_start=sum(org_str_len[:idx])\n",
    "    idx_end=sum(org_str_len[:idx+1])\n",
    "    tknIdx=[]\n",
    "    counter=0\n",
    "    non_stopwrds=[1 if idd not in stopwords.words('english') else 0 for idd in new_words]\n",
    "    for wrd in new_words:\n",
    "        if wrd in str_wrds2[idx_start+counter:idx_end]:\n",
    "            idd=str_wrds2[idx_start+counter:idx_end].index(wrd)\n",
    "            tknIdx.append(idx_start+idd+counter)\n",
    "            counter=counter+idd+1\n",
    "        else:\n",
    "            print('wrd not in tokenizer output', wrd)\n",
    "    TKN.append(tknIdx)\n",
    "    \n",
    "    \n",
    "    new_phonemes=[idd for idd in datadict['phonemes'][i] if idd[2]!='sp']\n",
    "    new_words=[idd for idd in datadict['words'][i] if idd[2][1:-1]!='sp']\n",
    "    datadict['phonemes'][i]=new_phonemes\n",
    "    datadict['words'][i]=new_words\n",
    "    ACT.append(activation_r[:,:,tknIdx,:, :])\n",
    "    start_wrds.append(np.array(non_stopwrds)[np.newaxis,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fresh-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 191)\n"
     ]
    }
   ],
   "source": [
    "print(start_wrds[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "iraqi-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191, 170, 2, 68, 94, 154, 192, 62, 167, 86, 88, 176, 139, 151, 198, 113, 226, 199, 190]\n",
      "226\n",
      "(6, 4, 226, 2, 60) (1, 226)\n"
     ]
    }
   ],
   "source": [
    "tokenL=[ idd.shape[2] for idd in ACT]\n",
    "maxL=max(tokenL)\n",
    "print(tokenL)\n",
    "print(maxL)\n",
    "## pad zeros\n",
    "ACT=[ np.concatenate( (idd, np.zeros((idd.shape[0],idd.shape[1] ,maxL- idd.shape[2], idd.shape[3], idd.shape[4]))),axis=2) for idd in ACT]\n",
    "start_wrds=[ np.concatenate( (idd, np.zeros((idd.shape[0],maxL- idd.shape[1]))),axis=1) for idd in start_wrds]\n",
    "\n",
    "print(ACT[0].shape,start_wrds[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "featured-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 6, 4, 226, 2, 60) (19, 1, 226)\n"
     ]
    }
   ],
   "source": [
    "activations=np.asarray(ACT)\n",
    "start_words=np.asarray(start_wrds)\n",
    "print(activations.shape,start_words.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "featured-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#print(stopwords.words('english'))\n",
    "i=5\n",
    "print(len(datadict['words'][i]), datadict['actv'][i].shape)\n",
    "new_words=[idd[2][1:-1].lower() for idd in datadict['words'][i] if idd[2][1:-1]!='sp']\n",
    "print(datadict['nonStopWrds'][i], len(datadict['nonStopWrds'][i]))\n",
    "\n",
    "wrdsStop=[item for idd,item in enumerate(new_words) if datadict['nonStopWrds'][i][idd]==1]\n",
    "print(wrdsStop)\n",
    "print(Window)'''\n",
    "\n",
    "from scipy.io import savemat\n",
    "datadict['actv']=activations\n",
    "datadict['nonStopWrds']=start_words\n",
    "datadict['window']=Window\n",
    "datadict['DRmethods']=DimRs\n",
    "Savename='../Data/after_aligner/hankGPT2'+modelplus+'FN'+sent_Window_N+'_'+pcaName+'.mat'\n",
    "# save the files to .mat \n",
    "\n",
    "savemat(Savename, datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fitted-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/after_aligner/hankGPT2-mediumFNWsentL_2LYR_DRs.mat\n"
     ]
    }
   ],
   "source": [
    "#np.asarray(datadict['nonStopWrds'])\n",
    "\n",
    "print(Savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "prompt-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10728, 2, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(Act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "natural-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00105901 -0.01824948 -0.00075396 ...  0.03721732  0.00622385\n",
      "  -0.11510081]\n",
      " [ 0.0023745  -0.01888404 -0.03326497 ... -0.00375302 -0.00503765\n",
      "  -0.00268101]\n",
      " [ 0.00026623 -0.01780795  0.00930467 ...  0.00940461 -0.00479928\n",
      "  -0.00301544]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0.         0.71377863 0.79773984 ... 0.90977645 0.97630911 0.94704813]\n",
      " [0.71377863 0.         0.55877124 ... 0.84535271 0.96201411 0.91030335]\n",
      " [0.79773984 0.55877124 0.         ... 0.88055337 0.99496197 0.98136305]\n",
      " ...\n",
      " [0.90977645 0.84535271 0.88055337 ... 0.         0.68462389 0.73704546]\n",
      " [0.97630911 0.96201411 0.99496197 ... 0.68462389 0.         0.72674615]\n",
      " [0.94704813 0.91030335 0.98136305 ... 0.73704546 0.72674615 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(activations[0,4,:,1,:])\n",
    "print(cosine_distances(np.squeeze(activation_zs[:,:,layer, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "driven-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying MDS:\n",
      "[[ 0.0187579  -0.13765596 -0.12693204 ... -0.05117913 -0.01593317\n",
      "   0.04371622]\n",
      " [ 0.00755739  0.00952576 -0.06225134 ...  0.02430559 -0.05198937\n",
      "  -0.03936052]\n",
      " [ 0.04149736 -0.10022929 -0.11822294 ... -0.12396124  0.08878997\n",
      "  -0.08924105]\n",
      " ...\n",
      " [ 0.03942662 -0.16168656 -0.11476682 ... -0.04855714 -0.04542532\n",
      "  -0.07711456]\n",
      " [ 0.13070307 -0.04437114 -0.14151299 ...  0.00726114  0.03311524\n",
      "  -0.15823054]\n",
      " [ 0.12124917  0.06571801 -0.02855442 ...  0.01663156 -0.04400266\n",
      "  -0.0293802 ]]\n"
     ]
    }
   ],
   "source": [
    "a=cosine_distances(np.squeeze(activation_zs[:,:,layer, :]))\n",
    "from sklearn.manifold import MDS\n",
    "# now we transform the activation matrix:\n",
    "print('applying MDS:')\n",
    "layer=1\n",
    "pca=MDS(n_components=ncmp,dissimilarity='precomputed')\n",
    "b=pca.fit_transform(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "everyday-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 60)\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-sound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
